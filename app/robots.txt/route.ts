import { NextRequest, NextResponse } from "next/server";
import type { MetadataRoute } from "next";
import { getCacheControlHeader } from "@utils/cache";

/**
 * robots.txt route handler with explicit cache control
 * 
 * Converted from app/robots.ts (Metadata API) to route handler to:
 * 1. Set explicit cache headers for CloudFront/SST (short TTL to prevent stale content)
 * 2. Ensure dynamic generation on every deployment
 * 3. Match the pattern used by sitemap.xml/route.ts for consistency
 * 
 * 2025 SEO Best Practices:
 * - Allow search engine crawlers (Googlebot, Bingbot, etc.)
 * - Block AI training crawlers (GPTBot, CCBot, etc.) to protect content
 * - Block /_next/ static files (JS chunks, CSS, build artifacts)
 * - Block /api/ routes (internal endpoints, not for indexing)
 * - Declare multiple sitemaps for comprehensive discovery
 * 
 * The host is dynamically determined for multi-domain support.
 */
export async function GET(request: NextRequest) {
  // Use NEXT_PUBLIC_SITE_URL for production, fallback for local development
  const siteUrl =
    process.env.NEXT_PUBLIC_SITE_URL || "https://www.esdeveniments.cat";

  const robotsConfig: MetadataRoute.Robots = {
    rules: [
      // Default rules for all crawlers (including search engines)
      {
        userAgent: "*",
        allow: "/",
        disallow: [
          // Block Next.js internal static files (JS chunks, CSS, build artifacts)
          // These were being indexed by Google Search Console
          "/_next/",
          // Block API routes - internal endpoints not meant for indexing
          "/api/",
          // Block internal/utility pages
          "/e2e/",
          "/offline/",
          // Block login/auth pages
          "/login/",
        ],
      },
      // Block AI TRAINING crawlers (2025 best practice)
      // These crawlers scrape content for LLM training without adding SEO value
      // NOTE: We ALLOW browsing/search crawlers (ChatGPT-User, Claude-Web) so we appear in AI searches
      {
        userAgent: "GPTBot", // OpenAI's training crawler
        disallow: ["/"],
      },
      {
        userAgent: "CCBot", // Common Crawl bot (used for AI training)
        disallow: ["/"],
      },
      {
        userAgent: "Google-Extended", // Google's AI training crawler (separate from search)
        disallow: ["/"],
      },
      {
        userAgent: "Bytespider", // ByteDance/TikTok AI crawler
        disallow: ["/"],
      },
      // ChatGPT-User and Claude-Web are ALLOWED (not listed) so we appear in AI-powered searches
    ],
    // Declare all sitemaps for comprehensive discovery
    sitemap: [
      `${siteUrl}/sitemap.xml`,
      `${siteUrl}/server-static-sitemap.xml`,
      `${siteUrl}/server-sitemap.xml`,
      `${siteUrl}/server-news-sitemap.xml`,
      `${siteUrl}/server-place-sitemap.xml`,
      `${siteUrl}/server-google-news-sitemap.xml`,
    ],
    // Host directive (some search engines use this for canonical domain)
    host: siteUrl,
  };

  // Convert MetadataRoute.Robots to robots.txt format
  const lines: string[] = [];

  // Add rules
  const rules = [robotsConfig.rules].flat().filter(Boolean);
  for (const rule of rules) {
    if (rule.userAgent) {
      lines.push(`User-Agent: ${rule.userAgent}`);
    }
    if (rule.allow) {
      const allowPaths = Array.isArray(rule.allow) ? rule.allow : [rule.allow];
      for (const path of allowPaths) {
        lines.push(`Allow: ${path}`);
      }
    }
    if (rule.disallow) {
      const disallowPaths = Array.isArray(rule.disallow)
        ? rule.disallow
        : [rule.disallow];
      for (const path of disallowPaths) {
        lines.push(`Disallow: ${path}`);
      }
    }
    lines.push(""); // Empty line between rules
  }

  // Add host directive
  if (robotsConfig.host) {
    lines.push(`Host: ${robotsConfig.host}`);
    lines.push("");
  }

  // Add sitemaps
  if (robotsConfig.sitemap) {
    const sitemaps = Array.isArray(robotsConfig.sitemap)
      ? robotsConfig.sitemap
      : [robotsConfig.sitemap];
    for (const sitemap of sitemaps) {
      lines.push(`Sitemap: ${sitemap}`);
    }
  }

  // Add a comment with timestamp to verify route handler is being used
  const timestamp = new Date().toISOString();
  lines.unshift(`# Generated by route handler at ${timestamp}`);
  lines.unshift("");

  const robotsTxt = lines.join("\n");

  // Set cache headers: short TTL at edge (5 minutes) to prevent stale content
  // Matches the pattern used by sitemap.xml/route.ts for consistency
  // If cache-busting is requested, disable caching entirely
  const cacheControl = getCacheControlHeader(request, 300);

  return new NextResponse(robotsTxt, {
    status: 200,
    headers: {
      "Content-Type": "text/plain; charset=utf-8",
      "Cache-Control": cacheControl,
      // Debug header to verify route handler is being used
      "X-Robots-Source": "route-handler-v2",
    },
  });
}

